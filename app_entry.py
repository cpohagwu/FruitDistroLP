{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "vBcUJMDGx1xl",
        "4j14Kmcepz2C",
        "8ZyIBQqzKDpA",
        "iHuCwINLrXms",
        "pFblArfru360",
        "snllsLrTvCAz",
        "NL0nSSOkonzf",
        "vwN-ZOaGIvQv"
      ],
      "authorship_tag": "ABX9TyObx0JPVitHfOKfZoeNIAAn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cpohagwu/FruitDistroLP/blob/main/app_entry.py\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Dependencies\n",
        "\n",
        "!pip install pulp --quiet\n",
        "!pip install gradio --quiet\n",
        "\n",
        "\"\"\"\n",
        "The Fruit Distribution Problem for the PuLP Modeller\n",
        "\n",
        "Authors: Collins Patrick Ohagwu, 1st Aug 2024\n",
        "\"\"\"\n",
        "# Import Dependencies\n",
        "import pulp # Import PuLP modeler functions\n",
        "import gradio as gr # Import Gradio for UI\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Data Loading and Inspection\n",
        "\n",
        "def assign_demand_nodes_by_type(df_demand, df_matrix, demand_n_matrix_col_id, demand_n_matrix_col_id_category):\n",
        "  matrix_demand_nodes_by_type_dict = df_matrix[[demand_n_matrix_col_id, demand_n_matrix_col_id_category]].set_index(demand_n_matrix_col_id).to_dict()[demand_n_matrix_col_id_category]\n",
        "  df_demand[demand_n_matrix_col_id_category] = df_demand[demand_n_matrix_col_id].map(matrix_demand_nodes_by_type_dict)\n",
        "\n",
        "  return df_demand\n",
        "\n",
        "def load_dataset(supply_dir, demand_dir, matrix_dir):\n",
        "  \"\"\"\n",
        "  Load the dataset from the given directories.\n",
        "  \"\"\"\n",
        "  df_supply = pd.read_csv(supply_dir)\n",
        "  df_demand = pd.read_csv(demand_dir)\n",
        "  df_matrix = pd.read_csv(matrix_dir)\n",
        "\n",
        "  return df_supply, df_demand, df_matrix\n",
        "\n",
        "### Preprocessing Functions\n",
        "# These functions ensure the data schema (with the currect data types) and check the nodes in `supply` and `demand` sheet against those of the `preference matrix`.\n",
        "\n",
        "def enforce_data_schema(df_supply, supply_col_id, supply_col_val_list, df_demand, demand_col_val, df_matrix, mx_col_demand_id, mx_col_demand_id_cat):\n",
        "  \"\"\"\n",
        "  Convert data types of pandas df columns to the correct types.\n",
        "  \"\"\"\n",
        "  df_supply[supply_col_id] = df_supply[supply_col_id].astype(str)\n",
        "  supply_node_list = df_supply[supply_col_id].unique().tolist()\n",
        "  for col in supply_col_val_list:\n",
        "    df_supply[col] = df_supply[col].astype(int)\n",
        "\n",
        "  df_demand[mx_col_demand_id] = df_demand[mx_col_demand_id].astype(str)\n",
        "  demand_node_list = df_demand[mx_col_demand_id].unique().tolist()\n",
        "  df_demand[demand_col_val] = df_demand[demand_col_val].astype(int)\n",
        "  df_demand[mx_col_demand_id_cat] = df_demand[mx_col_demand_id_cat].astype(str)\n",
        "\n",
        "  df_matrix[mx_col_demand_id] = df_matrix[mx_col_demand_id].astype(str)\n",
        "  matrix_demand_node_list = df_matrix[mx_col_demand_id].unique().tolist()\n",
        "  df_matrix[mx_col_demand_id_cat] = df_matrix[mx_col_demand_id_cat].astype(str)\n",
        "\n",
        "  # Convert all columns to float\n",
        "  matrix_supply_node_list = df_matrix.drop(columns=[mx_col_demand_id, mx_col_demand_id_cat]).columns.to_list()\n",
        "  for col in matrix_supply_node_list:\n",
        "    df_matrix[col] = df_matrix[col].astype(float)\n",
        "\n",
        "  return df_supply, supply_node_list, df_demand, demand_node_list, df_matrix, matrix_supply_node_list, matrix_demand_node_list\n",
        "\n",
        "### Check Nodes in Supply and Demand Sheet Against Pref. Matrix\n",
        "def check_matrix_completeness(df_supply, supply_node_list, df_demand, demand_node_list, df_matrix, matrix_supply_node_list, matrix_demand_node_list):\n",
        "  \"\"\"\n",
        "  Check that the Farm Codes in the supply sheet are present in the preference matrix.\n",
        "  Also check that the SKU's in the demand sheet are present in the preference matrix.\n",
        "  Else, remove any SKU's or Farm Codes that are not present in the preference matrix.\n",
        "  \"\"\"\n",
        "  ################################################\n",
        "  # SUPPLY SHEET\n",
        "  # Check that the Farm Codes in the supply sheet are present in the preference matrix\n",
        "  supply_node_not_in_matrix = [node for node in supply_node_list if node not in matrix_supply_node_list]\n",
        "  matrix_supply_node_not_in_supply = [node for node in matrix_supply_node_list if node not in supply_node_list]\n",
        "\n",
        "  # Instanciate the log messages\n",
        "  log_messages = []\n",
        "  if len(supply_node_not_in_matrix) > 0 | len(matrix_supply_node_not_in_supply) > 0:\n",
        "\n",
        "    log_messages.append(f'# Farm Codes in the supply sheet but not in the preference matrix: {len(supply_node_not_in_matrix)} \\n Node List: {supply_node_not_in_matrix}')\n",
        "    log_messages.append('WARNING! Values from the Supply Nodes above will not be assigned to any Demand Node.\\n')\n",
        "    log_messages.append(f'# Farm Codes in the preference matrix but not in the supply sheet: {len(matrix_supply_node_not_in_supply)} \\n Node List: {matrix_supply_node_not_in_supply}')\n",
        "    log_messages.append('==============================================================')\n",
        "    # Exlude nodes from supply sheet\n",
        "    df_supply = df_supply[~df_supply['Code'].isin(supply_node_not_in_matrix)]\n",
        "    # Exclude nodes from the preference matrix\n",
        "    df_matrix = df_matrix.drop(columns=matrix_supply_node_not_in_supply)\n",
        "\n",
        "  else:\n",
        "    log_messages.append('All Farm Codes in the Supply Sheet are present in the Preference Matrix.')\n",
        "    log_messages.append('==============================================================')\n",
        "\n",
        "  ################################################\n",
        "  # DEMAND SHEET\n",
        "  # Check that the SKU's in the demand sheet are present in the preference matrix\n",
        "  demand_node_not_in_matrix = [node for node in demand_node_list if node not in matrix_demand_node_list]\n",
        "  matrix_demand_node_not_in_demand = [node for node in matrix_demand_node_list if node not in demand_node_list]\n",
        "\n",
        "  if len(demand_node_not_in_matrix) > 0 | len(matrix_demand_node_not_in_demand) > 0:\n",
        "\n",
        "    log_messages.append(f'# SKU\\'s in the demand sheet but not in the preference matrix: {len(demand_node_not_in_matrix)} \\n Node List: {demand_node_not_in_matrix}')\n",
        "    log_messages.append('WARNING! Values in the Demand Nodes above will not be satisfied from any Supply Node.\\n')\n",
        "    log_messages.append(f'# SKU\\'s in the preference matrix but not in the demand sheet: {len(matrix_demand_node_not_in_demand)} \\n Node List: {matrix_demand_node_not_in_demand}')\n",
        "    log_messages.append('==============================================================')\n",
        "    # Exlude nodes from demand sheet\n",
        "    df_demand = df_demand[~df_demand['SKU'].isin(demand_node_not_in_matrix)]\n",
        "    # Exclude nodes from the preference matrix\n",
        "    df_matrix = df_matrix.drop(columns=matrix_demand_node_not_in_demand)\n",
        "\n",
        "  else:\n",
        "    log_messages.append('All SKU\\'s in the Demand Sheet are present in the Preference Matrix.')\n",
        "    log_messages.append('==============================================================')\n",
        "\n",
        "  return log_messages, df_supply, df_demand, df_matrix\n",
        "\n",
        "# #########################################\n",
        "# LP Model Functions\n",
        "'''\n",
        "  Functions to handle the creation of linear programming **descision variables, update the variables to include dummy demand nodes\n",
        "  (to handle excess supply) and dummy supply nodes (to handle excess demand), create and solve the LP problem, and interpret and output\n",
        "  the results as pandas dataframes**.\n",
        "'''\n",
        "\n",
        "### Descision Variables\n",
        "def generate_variable_dictionaries(df_supply: pd.DataFrame, supply_id: str, supply_val: str, df_demand: pd.DataFrame, demand_id: str, demand_val: str, df_matrix: pd.DataFrame):\n",
        "  \"\"\"\n",
        "  Generate dictionaries for decision variables\n",
        "  Args:\n",
        "    df_supply: df with supply data\n",
        "    supply_id: column name for supply id\n",
        "    supply_val: column name for supply value\n",
        "    df_demand: df with demand data\n",
        "    demand_id:  column name for demand id\n",
        "    demand_val: column name for demand value\n",
        "    df_matrix:  df for the preference matrix per supply (row indeces) and demand (column names)\n",
        "\n",
        "    Returns:\n",
        "    supply_dict: dictionary for the number of units of supply for each supply node\n",
        "    demand_dict: dictionary for the number of units of demand for each demand node\n",
        "    preference_dict: dictionary for the preference matrix\n",
        "  \"\"\"\n",
        "  # Initialize log messages\n",
        "  log_messages = []\n",
        "  log_messages.append(f'SOLVING FOR `{supply_val}` TYPE')\n",
        "  log_messages.append('\\n==============================================================\\n')\n",
        "\n",
        "  # Dictionary for the number of units of supply for each supply node\n",
        "  supply_dict = {row[supply_id]: row[supply_val] for _, row in df_supply.iterrows()}\n",
        "\n",
        "  # Dictionary for the number of units of demand for each demand node\n",
        "  demand_dict = {row[demand_id]: row[demand_val] for _, row in df_demand.iterrows()}\n",
        "\n",
        "  # Dictionary of dictionary for the preference matrix\n",
        "  df_matrix = df_matrix.transpose() # Transpose and use the first row as header\n",
        "  new_header = df_matrix.iloc[0] #grab the first row for the header\n",
        "  df_matrix = df_matrix[1:] #take the data less the header row\n",
        "  df_matrix.columns = new_header #set the header row as the df header\n",
        "  preference_dict = df_matrix.to_dict('index')\n",
        "\n",
        "  # Print the number of supply and demand nodes\n",
        "  log_messages.append('Before Dummy Update')\n",
        "  log_messages.append(f'# Supply Nodes: {len(supply_dict)}')\n",
        "  log_messages.append(f'# Demand Nodes: {len(demand_dict)}')\n",
        "  log_messages.append(f'Preference df Shape: {df_matrix.shape[0]} Supply Rows | {df_matrix.shape[1]} Demand Columns')\n",
        "\n",
        "  # Calculate the total supply and demand\n",
        "  log_messages.append(f'Total Supply: {int(sum(supply_dict.values())):,}')\n",
        "  log_messages.append(f'Total Demand: {int(sum(demand_dict.values())):,}')\n",
        "  log_messages.append('\\n==============================================================\\n')\n",
        "\n",
        "  return log_messages, supply_dict, demand_dict, preference_dict\n",
        "\n",
        "def update_vd_for_dummy_nodes(log_messages, supply_dict: dict, demand_dict: dict, preference_dict: dict):\n",
        "  \"\"\"\n",
        "  Update supply and demand dictionaries with dummy nodes for excess or deficit supply conditions\n",
        "  \"\"\"\n",
        "  # Calculate the total supply and demand\n",
        "  total_supply = sum(supply_dict.values())\n",
        "  total_demand = sum(demand_dict.values())\n",
        "\n",
        "  # Update demand nodes with Dummy nodes\n",
        "  dummy_demand_node = 'DummyDemandNode'\n",
        "  supply_excess = total_supply - total_demand\n",
        "\n",
        "  # Update demand dict with Dummy EXCESS demand (to cover excess supply)\n",
        "  if supply_excess > 0:\n",
        "    demand_dict[dummy_demand_node] = abs(supply_excess)\n",
        "    log_messages.append(f'Dummy Excess Demand: {abs(supply_excess):,}')\n",
        "\n",
        "  # Update supply nodes with Dummy nodes\n",
        "  dummy_supply_node = 'DummySupplyNode'\n",
        "\n",
        "  # Update supply dict with Dummy EXCESS supply (to cover excess demand)\n",
        "  if supply_excess < 0:\n",
        "    supply_dict[dummy_supply_node] = abs(supply_excess)\n",
        "    log_messages.append(f'Dummy Excess Supply: {abs(supply_excess):,}')\n",
        "\n",
        "  # Update preference dict with Dummy Supply and Demand nodes\n",
        "  preference_df = pd.DataFrame(preference_dict).T # as pandas dataframe for updates\n",
        "  # Add new dummy supply to the preference matrix if present in the supply dict keys (nodes)\n",
        "  if dummy_supply_node in supply_dict.keys():\n",
        "    preference_df.loc[dummy_supply_node] = 0\n",
        "  # Add new dummy demand to the preference matrix if present in the demand dict keys (nodes)\n",
        "  if dummy_demand_node in demand_dict.keys():\n",
        "    preference_df[dummy_demand_node] = 0\n",
        "  # Convert back to dictionary\n",
        "  preference_dict = preference_df.to_dict('index')\n",
        "\n",
        "  # Print the number of supply and demand nodes after updating\n",
        "  log_messages.append('After Dummy Update')\n",
        "  log_messages.append(f'# Supply Nodes: {len(supply_dict)}')\n",
        "  log_messages.append(f'# Demand Nodes: {len(demand_dict)}')\n",
        "  log_messages.append(f'Preference df Shape: {preference_df.shape[0]} Supply Rows | {preference_df.shape[1]} Demand Columns')\n",
        "\n",
        "  # Calculate the total supply and demand after updating\n",
        "  log_messages.append(f'Total Supply: {int(sum(supply_dict.values())):,}')\n",
        "  log_messages.append(f'Total Demand: {int(sum(demand_dict.values())):,}')\n",
        "  log_messages.append('\\n==============================================================\\n')\n",
        "\n",
        "  return log_messages, supply_dict, demand_dict, preference_dict\n",
        "\n",
        "### Problem Statements/ Objective Functions/ Constraints\n",
        "\n",
        "def create_and_solve_lp_problem(log_messages, supply_dict: dict, demand_dict: dict, preference_dict: dict):\n",
        "\n",
        "  \"\"\"\n",
        "  Create and solve the LP problem\n",
        "  \"\"\"\n",
        "\n",
        "  # Creates the 'prob' variable to contain the problem data\n",
        "  prob = pulp.LpProblem(\"Fruit_Distribution_Problem\", pulp.LpMaximize)\n",
        "\n",
        "  # Creates a list of tuples containing all the possible routes for transport\n",
        "  routes_tup = [(s, d) for s in supply_dict.keys() for d in demand_dict.keys()]\n",
        "\n",
        "  # A dictionary called 'Vars' is created to contain the referenced variables(the routes)\n",
        "  vars = pulp.LpVariable.dicts(\"Route\", (supply_dict.keys(), demand_dict.keys()), 0, None, pulp.LpInteger)\n",
        "\n",
        "  # The objective function is added to 'prob' first\n",
        "  prob += (\n",
        "      pulp.lpSum([vars[s][d] * preference_dict[s][d] for (s, d) in routes_tup]),\n",
        "      \"Sum_of_Preference_Matrix\",\n",
        "      )\n",
        "\n",
        "  # The supply maximum constraints are added to prob for each supply node\n",
        "  for s in supply_dict.keys():\n",
        "      prob += (\n",
        "          pulp.lpSum([vars[s][d] for d in demand_dict.keys()]) <= supply_dict[s],\n",
        "          f\"Sum_of_Fruits_out_of_Farm_{s}\",\n",
        "      )\n",
        "\n",
        "  # The demand minimum constraints are added to prob for each demand node\n",
        "  for d in demand_dict.keys():\n",
        "      prob += (\n",
        "          pulp.lpSum([vars[s][d] for s in supply_dict.keys()]) >= demand_dict[d],\n",
        "          f\"Sum_of_Fruits_into_SKU_{d}\",\n",
        "      )\n",
        "\n",
        "  # The problem is solved using PuLP's choice of Solver\n",
        "  prob.solve() # takes no argument, uses default solver\n",
        "\n",
        "  # The status of the solution is printed to the screen\n",
        "  log_messages.append(f\"Solution Status: {pulp.LpStatus[prob.status]}\")\n",
        "  log_messages.append('\\n==============================================================\\n')\n",
        "\n",
        "  return log_messages, prob\n",
        "\n",
        "def get_results(prob: pulp.LpProblem):\n",
        "  \"\"\"\n",
        "  Get results in matrix and direct form\n",
        "  \"\"\"\n",
        "\n",
        "  # Process matrix results, (all values in a grid form)\n",
        "  results = {}\n",
        "  # Each of the variables is printed with it's resolved optimum value\n",
        "  for route in prob.variables():\n",
        "    # print(f'{route.name}: {route.varValue}')\n",
        "    route_name = route.name.split(\"_\")\n",
        "    supply = route_name[1]\n",
        "    demand = route_name[2]\n",
        "\n",
        "    if supply not in results:\n",
        "      results[supply] = {}\n",
        "\n",
        "    results[supply][demand] = int(route.varValue)\n",
        "\n",
        "  df_matrix_results = pd.DataFrame(results)\n",
        "\n",
        "\n",
        "  # Process direct results, (only none zero values)\n",
        "  results = []\n",
        "  # Each of the variables is printed with it's resolved optimum value\n",
        "  for route in prob.variables():\n",
        "    # Only non zero values\n",
        "    if route.varValue > 0:\n",
        "\n",
        "      route_name = route.name.split(\"_\")\n",
        "      supply = route_name[1]\n",
        "      demand = route_name[2]\n",
        "\n",
        "      results_route = []\n",
        "      results_route.append(supply)\n",
        "      results_route.append(demand)\n",
        "      results_route.append(int(route.varValue))\n",
        "\n",
        "      results.append(results_route)\n",
        "\n",
        "    df_direct_results = pd.DataFrame(results, columns=['Supply (Farm Codes)', 'Demand (SKU)', 'Units (Boxes)'])\n",
        "\n",
        "  return df_matrix_results, df_direct_results\n",
        "\n",
        "### Call Linear Programming Functions with Functions\n",
        "\n",
        "def run_lp_model(df_supply: pd.DataFrame, supply_id: str, supply_col_val_list: list, df_demand: pd.DataFrame, demand_id: str, demand_val: str, df_matrix: pd.DataFrame):\n",
        "  \"\"\"\n",
        "  Run the LP model\n",
        "  \"\"\"\n",
        "  # Initialize model list\n",
        "  models = []\n",
        "  # Initialize log messages\n",
        "  log_messages = []\n",
        "  # Iterate through each supply value\n",
        "  for supply_val in supply_col_val_list:\n",
        "    # Generate dictionaries of decision variables\n",
        "    logs, supply_dict, demand_dict, preference_dict = generate_variable_dictionaries(df_supply, supply_id, supply_val, df_demand, demand_id, demand_val, df_matrix)\n",
        "    # Update supply and demand dictionaries with dummy nodes for excess or deficit supply conditions\n",
        "    logs, supply_dict, demand_dict, preference_dict = update_vd_for_dummy_nodes(logs, supply_dict, demand_dict, preference_dict)\n",
        "    # Create and solve lp problem\n",
        "    logs, model = create_and_solve_lp_problem(logs, supply_dict, demand_dict, preference_dict)\n",
        "    # Append model to list\n",
        "    models.append(model)\n",
        "    # Append logs to list\n",
        "    log_messages.append(logs)\n",
        "  return log_messages, models\n",
        "\n",
        "def process_model_results(models: list):\n",
        "  \"\"\"\n",
        "  Process the model results\n",
        "  \"\"\"\n",
        "  # Initialize results list\n",
        "  df_matrix_results = []\n",
        "  df_direct_results = []\n",
        "\n",
        "  # Initialize log messages\n",
        "  log_messages = []\n",
        "  log_messages.append('==============================================================')\n",
        "  log_messages.append('PROCESSING MODEL RESULTS')\n",
        "  log_messages.append('==============================================================')\n",
        "\n",
        "  count = 1\n",
        "\n",
        "  # Iterate through each model\n",
        "  for model in models:\n",
        "    # Get results in matrix and direct form\n",
        "    if model.status == 1:\n",
        "      df_matrix_result, df_direct_result = get_results(model)\n",
        "      df_matrix_results.append(df_matrix_result)\n",
        "      df_direct_results.append(df_direct_result)\n",
        "      log_messages.append(f'Problem {count} solved!')\n",
        "      # Write lp problem to file\n",
        "      model_name = f\"Fruit_Distribution_Problem_{count}.lp\"\n",
        "      model.writeLP(model_name)\n",
        "      log_messages.append(f\"The problem is written to {model_name}\")\n",
        "      log_messages.append('==============================================================')\n",
        "\n",
        "    else:\n",
        "      log_messages.append('Problem not solved!')\n",
        "      log_messages.append('==============================================================')\n",
        "\n",
        "    df_matrix_results_concat = pd.concat(df_matrix_results, axis=0)\n",
        "    df_direct_results_concat = pd.concat(df_direct_results, axis=0)\n",
        "\n",
        "    count += 1\n",
        "\n",
        "  return log_messages, df_matrix_results_concat, df_direct_results_concat\n",
        "\n",
        "# Gradio App\n",
        "\n",
        "def flatten_list(nested_list):\n",
        "  # Check if the list is nested\n",
        "  if any(isinstance(i, list) for i in nested_list):\n",
        "    # Flatten a nested list\n",
        "    return [item for sublist in nested_list for item in sublist]\n",
        "  else:\n",
        "    return nested_list\n",
        "\n",
        "def display_list(list_items):\n",
        "    # Convert list to a string with each item on a new line\n",
        "    list_string = \"\\n\".join(list_items)\n",
        "    return list_string\n",
        "\n",
        "# In run_lp_model, use the state variables\n",
        "def gr_run_lp_model(df_supply, supply_col_id, supply_col_val_list, df_demand, demand_n_matrix_col_id, demand_col_val, df_matrix):\n",
        "\n",
        "    import ast\n",
        "    # Convert string to list\n",
        "    supply_col_val_list = ast.literal_eval(supply_col_val_list)\n",
        "\n",
        "    # Run LP model\n",
        "    mod_logs, models = run_lp_model(df_supply, supply_col_id, supply_col_val_list, df_demand, demand_n_matrix_col_id, demand_col_val, df_matrix)\n",
        "\n",
        "    # Process model results\n",
        "    results_logs, df_matrix_results, df_direct_results = process_model_results(models)\n",
        "\n",
        "    # Flatten logs\n",
        "    logs = []\n",
        "    logs.append(flatten_list(mod_logs))\n",
        "    logs.append(flatten_list(results_logs))\n",
        "    logs = flatten_list(logs)\n",
        "\n",
        "    # Save the processed CSV for download\n",
        "    matrix_results_csv_path = '/matrix_results.csv'\n",
        "    direct_results_csv_path = '/direct_results.csv'\n",
        "    df_matrix_results.to_csv(matrix_results_csv_path, index=True)\n",
        "    df_direct_results.to_csv(direct_results_csv_path, index=True)\n",
        "\n",
        "    return display_list(logs), df_direct_results, matrix_results_csv_path, direct_results_csv_path\n",
        "\n",
        "def gr_process_files(supply_file, demand_file, matrix_file, supply_col_id, supply_col_val_list):\n",
        "  \"\"\"\n",
        "  Process the files\n",
        "  \"\"\"\n",
        "  # The following variables are defined based on domain knowledge of the dataset.\n",
        "  supply_col_id = 'Code' # This is the farm code from production.\n",
        "  supply_col_val_list = ['Regular', 'Pre Weighted'] # Also the fruit type:  `Regular`, `Pre Pesado`, etc.\n",
        "\n",
        "  demand_n_matrix_col_id = 'SKU' # This is the SKU from logistics.\n",
        "  demand_col_val = 'Volume' # This is the volume requested per SKU.\n",
        "  demand_n_matrix_col_id_category = 'Type' # This is the sub classification found on the `supply_col_val_list`.\n",
        "\n",
        "\n",
        "  # Load the files\n",
        "  df_supply, df_demand, df_matrix = load_dataset(supply_file.name, demand_file.name, matrix_file.name)\n",
        "  df_demand = assign_demand_nodes_by_type(df_demand, df_matrix, demand_n_matrix_col_id, demand_n_matrix_col_id_category)\n",
        "\n",
        "  # Filter fruit distribution by week and drop `Week` column\n",
        "  # Normally, this should not be needed since the dataset is refreshed each week.\n",
        "  WEEK = 'WK29'\n",
        "  df_supply = df_supply[df_supply['Week'] == WEEK].drop(columns=['Week']).fillna(0)\n",
        "  df_demand = df_demand[df_demand['Week'] == WEEK].drop(columns=['Week']).fillna(0)\n",
        "\n",
        "  df_supply, supply_node_list, df_demand, demand_node_list, df_matrix, matrix_supply_node_list, matrix_demand_node_list = enforce_data_schema(df_supply, supply_col_id, supply_col_val_list, df_demand, demand_col_val, df_matrix, demand_n_matrix_col_id, demand_n_matrix_col_id_category)\n",
        "  logs, df_supply, df_demand, df_matrix = check_matrix_completeness(df_supply, supply_node_list, df_demand, demand_node_list, df_matrix, matrix_supply_node_list, matrix_demand_node_list)\n",
        "\n",
        "  return display_list(logs), supply_col_id,  supply_col_val_list, df_supply, demand_n_matrix_col_id, demand_col_val, demand_n_matrix_col_id_category, df_demand, df_matrix\n",
        "\n",
        "# Gradio Interface\n",
        "with gr.Blocks() as app:\n",
        "    # Logo\n",
        "    img_url=\"https://upload.wikimedia.org/wikipedia/en/thumb/d/d5/Dole_Foods_Logo_Green_Leaf.svg/1280px-Dole_Foods_Logo_Green_Leaf.svg.png\"\n",
        "    gr.Image(value=img_url, width=100, height=100)\n",
        "\n",
        "    gr.Markdown(\"# Fruit Distribution App\")\n",
        "\n",
        "    ###############################################\n",
        "    gr.Markdown(\"## File Procesor\")\n",
        "    # CSV File Uploads\n",
        "    supply = gr.File(label=\"Upload Supply CSV File\")\n",
        "    demand = gr.File(label=\"Upload Demand CSV File\")\n",
        "    matrix = gr.File(label=\"Upload Matrix CSV File\")\n",
        "\n",
        "    # Process Button\n",
        "    process_button = gr.Button(\"Process Files\")\n",
        "\n",
        "    # Outputs\n",
        "    gr_logs = gr.Textbox(label=\"Data Processing Logs\")\n",
        "    gr_supply_col_id = gr.Textbox(label=\"Supply Column ID\")\n",
        "    gr_supply_col_val_list = gr.Textbox(label=\"Supply Column Value List\")\n",
        "    gr_df_supply = gr.Dataframe(label=\"Supply Dataframe\")\n",
        "\n",
        "    gr_demand_n_matrix_col_id = gr.Textbox(label=\"Demand N Matrix Column ID\")\n",
        "    gr_demand_col_val = gr.Textbox(label=\"Demand Column Value\")\n",
        "    gr_demand_n_matrix_col_id_category = gr.Textbox(label=\"Demand N Matrix Column ID Category\")\n",
        "    gr_df_demand = gr.Dataframe(label=\"Demand Dataframe\")\n",
        "\n",
        "    gr_df_matrix = gr.Dataframe(label=\"Matrix Dataframe\")\n",
        "\n",
        "    # Link function to button\n",
        "    process_button.click(fn=gr_process_files,\n",
        "                         inputs=[supply, demand, matrix],\n",
        "                         outputs=[gr_logs,\n",
        "                                  gr_supply_col_id, gr_supply_col_val_list, gr_df_supply,\n",
        "                                  gr_demand_n_matrix_col_id, gr_demand_col_val, gr_demand_n_matrix_col_id_category, gr_df_demand,\n",
        "                                  gr_df_matrix])\n",
        "\n",
        "\n",
        "    ###############################################\n",
        "    gr.Markdown(\"## Model Builder\")\n",
        "    # Run Model Button\n",
        "    run_model_button = gr.Button(\"Run Model\")\n",
        "\n",
        "    # Outputs\n",
        "    out_logs = gr.Textbox(label=\"Model Building Logs\")\n",
        "    out_df_direct_results = gr.Dataframe(label=\"Direct Results Dataframe\")\n",
        "\n",
        "    download_matrix_results = gr.File(label=\"Download Matrix Results\")\n",
        "    download_direct_results = gr.File(label=\"Download Direct Results\")\n",
        "\n",
        "    # Link function to button\n",
        "    run_model_button.click(fn=gr_run_lp_model,\n",
        "                           inputs=[gr_df_supply, gr_supply_col_id, gr_supply_col_val_list,\n",
        "                                   gr_df_demand, gr_demand_n_matrix_col_id, gr_demand_col_val,\n",
        "                                   gr_df_matrix],\n",
        "                           outputs=[out_logs,\n",
        "                                    out_df_direct_results,\n",
        "                                    download_matrix_results, download_direct_results])\n",
        "\n",
        "# Launch the app\n",
        "app.launch()"
      ],
      "metadata": {
        "id": "g7vfa4Ub8U4I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b87bcc4e-1614-4fdb-f0a3-6cb0e7a5e49b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gradio/utils.py:1002: UserWarning: Expected 5 arguments for function <function gr_process_files at 0x7b417c74e290>, received 3.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gradio/utils.py:1006: UserWarning: Expected at least 5 arguments for function <function gr_process_files at 0x7b417c74e290>, received 3.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Results Inspection"
      ],
      "metadata": {
        "id": "5MTiLKMqu64E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "NADXUwQ4U6si"
      }
    }
  ]
}